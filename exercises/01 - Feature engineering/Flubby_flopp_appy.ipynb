{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Updated 2019.09.05\n",
    "\n",
    "@author: Kristian Hovde Liland\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " As the world leading producer of Flubby Flops (TM) you want to predict\n",
    " the flubberiness from the raw material analyses and input settings of \n",
    " the Flubmaster EX. The following features are available:\n",
    " + Raw materials\n",
    "     - flostard\n",
    "     - flüber\n",
    "     - lard\n",
    " + Process attributes\n",
    "     - floppiness\n",
    "     - process start\n",
    "     - boiling stop\n",
    "     - stretching stop\n",
    " + Response\n",
    "     - flubberiness\n",
    " \n",
    " You have been introduced to several techniques in feature engineering in \n",
    " your days at the university with regard to deriving new features, \n",
    " recoding, transforming, and making interactions. ++\n",
    " \n",
    " Use the full dataset to predict the response, i.e. no validation or hold-out\n",
    " for this exercise (ordinary linear regression should suffice, but other tools \n",
    " may work). Apply your feature engineering tools and try to achieve predictions\n",
    " that are less than 10^-3 off target.\n",
    " During the exploration, visualise and ponder on the attributes of the\n",
    " available features.\n",
    " \n",
    " Data are available as a CSV file with latin1 encoding.\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in Data Preprocessing\n",
    "Step 1 : Import the libraries\n",
    "\n",
    "Step 2 : Import the data-set\n",
    "\n",
    "Step 3 : Check out the missing values\n",
    "\n",
    "Step 4 : See the Categorical Values\n",
    "\n",
    "Step 5 : Splitting the data-set into Training and Test Set\n",
    "\n",
    "Step 6 : Feature Scaling\n",
    "\n",
    "# ![ML.png](attachment:ML.png)\n",
    "# ![ml.jpeg](attachment:ml.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>process_start</th>\n",
       "      <th>boiling_stop</th>\n",
       "      <th>stretch_stop</th>\n",
       "      <th>floppiness</th>\n",
       "      <th>flostard</th>\n",
       "      <th>flüber</th>\n",
       "      <th>lard</th>\n",
       "      <th>flubberiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-29 01:57:00</td>\n",
       "      <td>2018-06-29 04:06:00</td>\n",
       "      <td>2018-06-29 04:33:00</td>\n",
       "      <td>high</td>\n",
       "      <td>0.726494</td>\n",
       "      <td>20.667655</td>\n",
       "      <td>19438.097842</td>\n",
       "      <td>596934.441785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-29 03:44:00</td>\n",
       "      <td>2018-06-29 05:53:00</td>\n",
       "      <td>2018-06-29 06:16:00</td>\n",
       "      <td>low</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>19.199460</td>\n",
       "      <td>20082.661675</td>\n",
       "      <td>647730.495391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-29 05:31:00</td>\n",
       "      <td>2018-06-29 07:34:00</td>\n",
       "      <td>2018-06-29 07:59:00</td>\n",
       "      <td>low</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>20.399001</td>\n",
       "      <td>19184.709928</td>\n",
       "      <td>537041.204320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-29 05:49:00</td>\n",
       "      <td>2018-06-29 07:49:00</td>\n",
       "      <td>2018-06-29 08:10:00</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.188165</td>\n",
       "      <td>20.363044</td>\n",
       "      <td>18524.828633</td>\n",
       "      <td>588746.939774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-29 07:04:00</td>\n",
       "      <td>2018-06-29 09:05:00</td>\n",
       "      <td>2018-06-29 09:34:00</td>\n",
       "      <td>low</td>\n",
       "      <td>1.156062</td>\n",
       "      <td>21.362930</td>\n",
       "      <td>21568.106683</td>\n",
       "      <td>542085.676371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        process_start         boiling_stop         stretch_stop  \\\n",
       "0           0  2018-06-29 01:57:00  2018-06-29 04:06:00  2018-06-29 04:33:00   \n",
       "1           1  2018-06-29 03:44:00  2018-06-29 05:53:00  2018-06-29 06:16:00   \n",
       "2           2  2018-06-29 05:31:00  2018-06-29 07:34:00  2018-06-29 07:59:00   \n",
       "3           3  2018-06-29 05:49:00  2018-06-29 07:49:00  2018-06-29 08:10:00   \n",
       "4           4  2018-06-29 07:04:00  2018-06-29 09:05:00  2018-06-29 09:34:00   \n",
       "\n",
       "  floppiness  flostard     flüber          lard   flubberiness  \n",
       "0       high  0.726494  20.667655  19438.097842  596934.441785  \n",
       "1        low  0.845524  19.199460  20082.661675  647730.495391  \n",
       "2        low  0.028887  20.399001  19184.709928  537041.204320  \n",
       "3     medium  0.188165  20.363044  18524.828633  588746.939774  \n",
       "4        low  1.156062  21.362930  21568.106683  542085.676371  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Flubby_Flops.csv', encoding = \"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()    # seems 0 is missing in each column\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# +\n",
    "# check the missing value\n",
    "\n",
    "# mark all missing values\n",
    "#data.replace('?', nan, inplace=True)\n",
    "\n",
    "\n",
    "# +\n",
    "#data = pd.read_csv('Flubby_Flops.csv', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'processstart':[0,1]}, index_col=['processstart'],encoding = \"ISO-8859-1\")\n",
    "\n",
    "#data.head()\n",
    "\n",
    "# +\n",
    "# convert feature 'process_start', 'boiling_stop', 'stretch_stop', timestamp into numeric\n",
    "\n",
    "#data_process = pd.DataFrame({'process_start': pd.date_range('2018-06-29 01:57:00', periods=987)})\n",
    "#data\n",
    "data['PS'] = pd.to_datetime(data.process_start)\n",
    "data['BS'] = pd.to_datetime(data.boiling_stop)\n",
    "data['SST'] = pd.to_datetime(data.stretch_stop)\n",
    "data\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "data.drop(columns=['process_start', 'boiling_stop', 'stretch_stop'], axis=1, inplace= True)\n",
    "data.head()\n",
    "\n",
    "#Drop unnecesary features from data and decide the features\n",
    "data.drop(data.iloc[: , 0:1], axis=1, inplace= True)\n",
    "data.head()\n",
    "\n",
    "data.dtypes\n",
    "\n",
    "# replace catagorical features (floppiness) with binary valaues\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "data.iloc[:,0] = label_enc.fit_transform(data.iloc[:,0])\n",
    "data\n",
    "\n",
    "dummy = pd.get_dummies(data.iloc[:,0])\n",
    "\n",
    "dummy.head()\n",
    "\n",
    "\n",
    "dummy.shape\n",
    "\n",
    "data2 = pd.concat([data, dummy])\n",
    "\n",
    "data2.head()\n",
    "\n",
    "data3 = data.join([dummy])\n",
    "\n",
    "data3.head()\n",
    "\n",
    "data3 = data3.drop(columns=['floppiness'])\n",
    "\n",
    "data3.head()\n",
    "\n",
    "\n",
    "# +\n",
    "# convert timestamp_to_float\n",
    "\n",
    "def convert_to_float(a):\n",
    "    return time.mktime(t.timetuple(a))\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = data3.iloc[:,:] #independent columns\n",
    "\n",
    "\n",
    "X = X.drop(columns=['flubberiness'])\n",
    "X.head()\n",
    "\n",
    "Y = data3.iloc[:,3] \n",
    "\n",
    "   #target column i.e price range\n",
    "Y.head()\n",
    "\n",
    "import seaborn as sns\n",
    "#get correlations of each features in dataset\n",
    "corrmat = X.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(10,8))\n",
    "#plot heat map\n",
    "g=sns.heatmap(X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "\n",
    "model = LinearRegression()\n",
    "model = model.fit(X,Y)\n",
    "\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "\n",
    "# dummy_1 = pd.get_dummies(data_1['floppiness'])\n",
    "\n",
    "\n",
    "# +\n",
    "#dummy_1\n",
    "\n",
    "# +\n",
    "#data_new = pd.concat([data_1, dummy_1], axis=1)\n",
    "\n",
    "# +\n",
    "#data_new\n",
    "\n",
    "# +\n",
    "#data.drop(data.iloc[:, 17:20], axis=1)\n",
    "\n",
    "# +\n",
    "#data\n",
    "# -\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_flubby)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
